// This file is automatically generated.
#include <ClassRegistry.h>
#include <StringMapParameterNode.h>
#include <ZlibResourceDictionary.h>
#include <map>
#include <nvneural/CodeGenTypes.h>
#include <nvneural/CoreHelpers.h>
#include <nvneural/NetworkTypes.h>
#include <nvneural/layers/IConvolutionLayer.h>
#include <nvneural/layers/IPoolingLayer.h>
#include <nvneural/layers/IStandardInputLayer.h>
#include <string>

#define CHECK_NETWORK_VIOLATION(network_) \
do \
{ \
    if ((network_)->buildModeRestrictionViolated()) \
    { \
        nvneural::DefaultLogger()->logError(0, "%s", (network_)->getLastBuildModeViolationMessage()); \
        return nvneural::NeuralResult::Failure; \
    } \
} while (false)

nvneural::NeuralResult BuildNetwork_OIDN(nvneural::RefPtr<nvneural::INetwork> pNetwork, const nvneural::IClassRegistry* pRegistry)
{
    nvneural::RefPtr<nvneural::INetwork3> pNetwork3 = pNetwork.as<nvneural::INetwork3>();
    if (!pNetwork3)
    {
        nvneural::DefaultLogger()->logError(0, "Failed to cast network pointer to INetwork3");
        return nvneural::NeuralResult::Failure;
    }
    nvneural::NeuralResult status;

    status = pNetwork->setNetworkName("OIDN");
    if (nvneural::failed(status)) return status;

    // Layer pointers
    nvneural::RefPtr<nvneural::ILayer> pLayer_input;
    nvneural::RefPtr<nvneural::ILayer> pLayer_enc_conv0;
    nvneural::RefPtr<nvneural::ILayer> pLayer_enc_conv1;
    nvneural::RefPtr<nvneural::ILayer> pLayer_pool1;
    nvneural::RefPtr<nvneural::ILayer> pLayer_enc_conv2;
    nvneural::RefPtr<nvneural::ILayer> pLayer_pool2;
    nvneural::RefPtr<nvneural::ILayer> pLayer_enc_conv3;
    nvneural::RefPtr<nvneural::ILayer> pLayer_pool3;
    nvneural::RefPtr<nvneural::ILayer> pLayer_enc_conv4;
    nvneural::RefPtr<nvneural::ILayer> pLayer_pool4;
    nvneural::RefPtr<nvneural::ILayer> pLayer_enc_conv5a;
    nvneural::RefPtr<nvneural::ILayer> pLayer_enc_conv5b;
    nvneural::RefPtr<nvneural::ILayer> pLayer_upsample4;
    nvneural::RefPtr<nvneural::ILayer> pLayer_concat;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv4a;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv4b;
    nvneural::RefPtr<nvneural::ILayer> pLayer_upsample3;
    nvneural::RefPtr<nvneural::ILayer> pLayer_conca3;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv3a;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv3b;
    nvneural::RefPtr<nvneural::ILayer> pLayer_upsample2;
    nvneural::RefPtr<nvneural::ILayer> pLayer_conca2;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv2a;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv2b;
    nvneural::RefPtr<nvneural::ILayer> pLayer_upsample1;
    nvneural::RefPtr<nvneural::ILayer> pLayer_conca1;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv1a;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv1b;
    nvneural::RefPtr<nvneural::ILayer> pLayer_dec_conv0;
    nvneural::RefPtr<nvneural::ILayer> pLayer_output;

    // Initialize input
    {
        pRegistry->createObject(pLayer_input.put_refobject(),"com.nvidia.layers.input.cuda");
        if (!pLayer_input)
        {
            nvneural::DefaultLogger()->logError(0, "input: could not create object com.nvidia.layers.input.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_input->setName("input");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pInputLayer_input = pLayer_input.as<nvneural::IStandardInputLayer>();
        if (!pInputLayer_input)
        {
            nvneural::DefaultLogger()->logError(0, "%s: Not an input layer", pLayer_input->name());
            return nvneural::NeuralResult::Failure;
        }
        pInputLayer_input->setPlaceholderSize(nvneural::TensorDimension{1u, 3u, 688u, 1040u});
        pInputLayer_input->setImagesUseAlpha(false);
        pInputLayer_input->setTilingFactor(16);
        pInputLayer_input->setImageShift(0.000000f);

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_input.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize enc_conv0
    {
        pRegistry->createObject(pLayer_enc_conv0.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_enc_conv0)
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv0: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv0->setName("enc_conv0");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv0->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv0->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_enc_conv0_conv = pLayer_enc_conv0.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_enc_conv0_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer enc_conv0");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv0_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv0: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv0_conv->setFeatureCount(32);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv0: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv0_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv0: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv0_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv0: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv0_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv0: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv0_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv0: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_enc_conv0.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize enc_conv1
    {
        pRegistry->createObject(pLayer_enc_conv1.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_enc_conv1)
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv1: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv1->setName("enc_conv1");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv1->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv1->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_enc_conv1_conv = pLayer_enc_conv1.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_enc_conv1_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer enc_conv1");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv1_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv1: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv1_conv->setFeatureCount(32);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv1: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv1_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv1: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv1_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv1: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv1_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv1: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv1_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv1: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_enc_conv1.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize pool1
    {
        pRegistry->createObject(pLayer_pool1.put_refobject(),"com.nvidia.layers.pooling.cuda");
        if (!pLayer_pool1)
        {
            nvneural::DefaultLogger()->logError(0, "pool1: could not create object com.nvidia.layers.pooling.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool1->setName("pool1");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pLayer_pool1_pool = pLayer_pool1.as<nvneural::IPoolingLayer>();
        if (!pLayer_pool1_pool)
        {
            nvneural::DefaultLogger()->logError(0, "pool1: cannot retrieve IPoolingLayer interface");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool1_pool->setStartPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool1: could not set start padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool1_pool->setEndPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool1: could not set end padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool1_pool->setStride(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool1: could not set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool1_pool->setKernelSize(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool1: could not set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool1_pool->setPoolingType(nvneural::PoolType::Max);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool1: could not set pooling operation");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_pool1.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize enc_conv2
    {
        pRegistry->createObject(pLayer_enc_conv2.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_enc_conv2)
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv2: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv2->setName("enc_conv2");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv2->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv2->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_enc_conv2_conv = pLayer_enc_conv2.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_enc_conv2_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer enc_conv2");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv2_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv2: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv2_conv->setFeatureCount(48);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv2: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv2_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv2: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv2_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv2: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv2_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv2: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv2_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv2: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_enc_conv2.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize pool2
    {
        pRegistry->createObject(pLayer_pool2.put_refobject(),"com.nvidia.layers.pooling.cuda");
        if (!pLayer_pool2)
        {
            nvneural::DefaultLogger()->logError(0, "pool2: could not create object com.nvidia.layers.pooling.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool2->setName("pool2");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pLayer_pool2_pool = pLayer_pool2.as<nvneural::IPoolingLayer>();
        if (!pLayer_pool2_pool)
        {
            nvneural::DefaultLogger()->logError(0, "pool2: cannot retrieve IPoolingLayer interface");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool2_pool->setStartPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool2: could not set start padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool2_pool->setEndPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool2: could not set end padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool2_pool->setStride(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool2: could not set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool2_pool->setKernelSize(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool2: could not set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool2_pool->setPoolingType(nvneural::PoolType::Max);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool2: could not set pooling operation");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_pool2.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize enc_conv3
    {
        pRegistry->createObject(pLayer_enc_conv3.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_enc_conv3)
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv3: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv3->setName("enc_conv3");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv3->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv3->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_enc_conv3_conv = pLayer_enc_conv3.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_enc_conv3_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer enc_conv3");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv3_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv3: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv3_conv->setFeatureCount(64);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv3: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv3_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv3: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv3_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv3: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv3_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv3: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv3_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv3: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_enc_conv3.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize pool3
    {
        pRegistry->createObject(pLayer_pool3.put_refobject(),"com.nvidia.layers.pooling.cuda");
        if (!pLayer_pool3)
        {
            nvneural::DefaultLogger()->logError(0, "pool3: could not create object com.nvidia.layers.pooling.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool3->setName("pool3");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pLayer_pool3_pool = pLayer_pool3.as<nvneural::IPoolingLayer>();
        if (!pLayer_pool3_pool)
        {
            nvneural::DefaultLogger()->logError(0, "pool3: cannot retrieve IPoolingLayer interface");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool3_pool->setStartPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool3: could not set start padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool3_pool->setEndPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool3: could not set end padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool3_pool->setStride(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool3: could not set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool3_pool->setKernelSize(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool3: could not set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool3_pool->setPoolingType(nvneural::PoolType::Max);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool3: could not set pooling operation");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_pool3.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize enc_conv4
    {
        pRegistry->createObject(pLayer_enc_conv4.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_enc_conv4)
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv4: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv4->setName("enc_conv4");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv4->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv4->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_enc_conv4_conv = pLayer_enc_conv4.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_enc_conv4_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer enc_conv4");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv4_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv4: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv4_conv->setFeatureCount(80);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv4: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv4_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv4: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv4_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv4: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv4_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv4: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv4_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv4: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_enc_conv4.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize pool4
    {
        pRegistry->createObject(pLayer_pool4.put_refobject(),"com.nvidia.layers.pooling.cuda");
        if (!pLayer_pool4)
        {
            nvneural::DefaultLogger()->logError(0, "pool4: could not create object com.nvidia.layers.pooling.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool4->setName("pool4");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pLayer_pool4_pool = pLayer_pool4.as<nvneural::IPoolingLayer>();
        if (!pLayer_pool4_pool)
        {
            nvneural::DefaultLogger()->logError(0, "pool4: cannot retrieve IPoolingLayer interface");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool4_pool->setStartPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool4: could not set start padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool4_pool->setEndPadding(0, 0);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool4: could not set end padding");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool4_pool->setStride(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool4: could not set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool4_pool->setKernelSize(2, 2);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool4: could not set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_pool4_pool->setPoolingType(nvneural::PoolType::Max);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "pool4: could not set pooling operation");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_pool4.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize enc_conv5a
    {
        pRegistry->createObject(pLayer_enc_conv5a.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_enc_conv5a)
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5a: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5a->setName("enc_conv5a");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv5a->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv5a->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_enc_conv5a_conv = pLayer_enc_conv5a.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_enc_conv5a_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer enc_conv5a");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5a_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5a: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5a_conv->setFeatureCount(96);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5a: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5a_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5a: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5a_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5a: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5a_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5a: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5a_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5a: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_enc_conv5a.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize enc_conv5b
    {
        pRegistry->createObject(pLayer_enc_conv5b.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_enc_conv5b)
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5b: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5b->setName("enc_conv5b");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv5b->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv5b->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_enc_conv5b_conv = pLayer_enc_conv5b.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_enc_conv5b_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer enc_conv5b");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5b_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5b: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5b_conv->setFeatureCount(96);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5b: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5b_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5b: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5b_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5b: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5b_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5b: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_enc_conv5b_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "enc_conv5b: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_enc_conv5b.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize upsample4
    {
        pRegistry->createObject(pLayer_upsample4.put_refobject(),"com.nvidia.layers.upscale.cuda");
        if (!pLayer_upsample4)
        {
            nvneural::DefaultLogger()->logError(0, "upsample4: could not create object com.nvidia.layers.upscale.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_upsample4->setName("upsample4");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "factor", "2x2" },
            { "fixed_upscale", "" },
            { "method", "nearest" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_upsample4->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_upsample4.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize concat
    {
        pRegistry->createObject(pLayer_concat.put_refobject(),"com.nvidia.layers.concatenation.cuda");
        if (!pLayer_concat)
        {
            nvneural::DefaultLogger()->logError(0, "concat: could not create object com.nvidia.layers.concatenation.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_concat->setName("concat");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "axis", "1" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_concat->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_concat.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv4a
    {
        pRegistry->createObject(pLayer_dec_conv4a.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv4a)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4a: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4a->setName("dec_conv4a");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv4a->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv4a->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv4a_conv = pLayer_dec_conv4a.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv4a_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv4a");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4a_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4a: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4a_conv->setFeatureCount(112);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4a: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4a_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4a: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4a_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4a: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4a_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4a: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4a_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4a: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv4a.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv4b
    {
        pRegistry->createObject(pLayer_dec_conv4b.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv4b)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4b: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4b->setName("dec_conv4b");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv4b->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv4b->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv4b_conv = pLayer_dec_conv4b.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv4b_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv4b");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4b_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4b: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4b_conv->setFeatureCount(112);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4b: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4b_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4b: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4b_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4b: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4b_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4b: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv4b_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv4b: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv4b.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize upsample3
    {
        pRegistry->createObject(pLayer_upsample3.put_refobject(),"com.nvidia.layers.upscale.cuda");
        if (!pLayer_upsample3)
        {
            nvneural::DefaultLogger()->logError(0, "upsample3: could not create object com.nvidia.layers.upscale.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_upsample3->setName("upsample3");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "factor", "2x2" },
            { "fixed_upscale", "" },
            { "method", "nearest" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_upsample3->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_upsample3.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize conca3
    {
        pRegistry->createObject(pLayer_conca3.put_refobject(),"com.nvidia.layers.concatenation.cuda");
        if (!pLayer_conca3)
        {
            nvneural::DefaultLogger()->logError(0, "conca3: could not create object com.nvidia.layers.concatenation.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_conca3->setName("conca3");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "axis", "1" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_conca3->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_conca3.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv3a
    {
        pRegistry->createObject(pLayer_dec_conv3a.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv3a)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3a: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3a->setName("dec_conv3a");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv3a->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv3a->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv3a_conv = pLayer_dec_conv3a.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv3a_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv3a");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3a_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3a: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3a_conv->setFeatureCount(96);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3a: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3a_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3a: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3a_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3a: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3a_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3a: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3a_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3a: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv3a.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv3b
    {
        pRegistry->createObject(pLayer_dec_conv3b.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv3b)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3b: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3b->setName("dec_conv3b");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv3b->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv3b->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv3b_conv = pLayer_dec_conv3b.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv3b_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv3b");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3b_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3b: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3b_conv->setFeatureCount(96);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3b: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3b_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3b: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3b_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3b: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3b_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3b: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv3b_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv3b: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv3b.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize upsample2
    {
        pRegistry->createObject(pLayer_upsample2.put_refobject(),"com.nvidia.layers.upscale.cuda");
        if (!pLayer_upsample2)
        {
            nvneural::DefaultLogger()->logError(0, "upsample2: could not create object com.nvidia.layers.upscale.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_upsample2->setName("upsample2");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "factor", "2x2" },
            { "fixed_upscale", "" },
            { "method", "nearest" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_upsample2->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_upsample2.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize conca2
    {
        pRegistry->createObject(pLayer_conca2.put_refobject(),"com.nvidia.layers.concatenation.cuda");
        if (!pLayer_conca2)
        {
            nvneural::DefaultLogger()->logError(0, "conca2: could not create object com.nvidia.layers.concatenation.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_conca2->setName("conca2");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "axis", "1" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_conca2->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_conca2.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv2a
    {
        pRegistry->createObject(pLayer_dec_conv2a.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv2a)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2a: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2a->setName("dec_conv2a");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv2a->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv2a->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv2a_conv = pLayer_dec_conv2a.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv2a_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv2a");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2a_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2a: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2a_conv->setFeatureCount(64);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2a: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2a_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2a: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2a_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2a: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2a_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2a: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2a_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2a: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv2a.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv2b
    {
        pRegistry->createObject(pLayer_dec_conv2b.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv2b)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2b: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2b->setName("dec_conv2b");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv2b->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv2b->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv2b_conv = pLayer_dec_conv2b.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv2b_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv2b");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2b_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2b: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2b_conv->setFeatureCount(64);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2b: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2b_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2b: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2b_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2b: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2b_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2b: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv2b_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv2b: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv2b.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize upsample1
    {
        pRegistry->createObject(pLayer_upsample1.put_refobject(),"com.nvidia.layers.upscale.cuda");
        if (!pLayer_upsample1)
        {
            nvneural::DefaultLogger()->logError(0, "upsample1: could not create object com.nvidia.layers.upscale.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_upsample1->setName("upsample1");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "factor", "2x2" },
            { "fixed_upscale", "" },
            { "method", "nearest" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_upsample1->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_upsample1.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize conca1
    {
        pRegistry->createObject(pLayer_conca1.put_refobject(),"com.nvidia.layers.concatenation.cuda");
        if (!pLayer_conca1)
        {
            nvneural::DefaultLogger()->logError(0, "conca1: could not create object com.nvidia.layers.concatenation.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_conca1->setName("conca1");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "axis", "1" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_conca1->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_conca1.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv1a
    {
        pRegistry->createObject(pLayer_dec_conv1a.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv1a)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1a: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1a->setName("dec_conv1a");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv1a->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv1a->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv1a_conv = pLayer_dec_conv1a.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv1a_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv1a");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1a_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1a: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1a_conv->setFeatureCount(64);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1a: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1a_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1a: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1a_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1a: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1a_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1a: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1a_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1a: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv1a.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv1b
    {
        pRegistry->createObject(pLayer_dec_conv1b.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv1b)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1b: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1b->setName("dec_conv1b");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv1b->setActivationFunction(static_cast<nvneural::ActivationFunctionId>(0x1u)); // relu
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv1b->setActivationCoefficient(0, 0.f);
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;

        const auto pLayer_dec_conv1b_conv = pLayer_dec_conv1b.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv1b_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv1b");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1b_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1b: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1b_conv->setFeatureCount(32);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1b: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1b_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1b: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1b_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1b: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1b_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1b: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv1b_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv1b: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv1b.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize dec_conv0
    {
        pRegistry->createObject(pLayer_dec_conv0.put_refobject(),"com.nvidia.layers.convolution.cuda");
        if (!pLayer_dec_conv0)
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv0: could not create object com.nvidia.layers.convolution.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv0->setName("dec_conv0");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pLayer_dec_conv0_conv = pLayer_dec_conv0.as<nvneural::IConvolutionLayer2>();
        if (!pLayer_dec_conv0_conv)
        {
            nvneural::DefaultLogger()->logError(0, "cannot retrieve IConvolutionLayer2 interface from layer dec_conv0");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv0_conv->setKernelSize(3, 3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv0: unable to set kernel size");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv0_conv->setFeatureCount(3);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv0: unable to set feature count");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv0_conv->setStride(1, 1);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv0: unable to set stride");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv0_conv->setPaddingMode(nvneural::ConvolutionPaddingMode::Same);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv0: unable to set padding mode");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv0_conv->setPaddingDimension(nvneural::TensorDimension(0, 0, 1, 1));
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv0: unable to set padding dimension");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_dec_conv0_conv->applyBias(true);
        if (nvneural::failed(status))
        {
            nvneural::DefaultLogger()->logError(0, "dec_conv0: unable to set bias");
            return nvneural::NeuralResult::Failure;
        }

        CHECK_NETWORK_VIOLATION(pNetwork3);
        status = pNetwork->pushLayer(pLayer_dec_conv0.get());
        if (nvneural::failed(status)) return status;
    }
    // Initialize output
    {
        pRegistry->createObject(pLayer_output.put_refobject(),"com.nvidia.layers.slice.cuda");
        if (!pLayer_output)
        {
            nvneural::DefaultLogger()->logError(0, "output: could not create object com.nvidia.layers.slice.cuda");
            return nvneural::NeuralResult::Failure;
        }
        status = pLayer_output->setName("output");
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        const auto pParameterNode = nvneural::make_refobject<nvneural::StringMapParameterNode>(nvneural::StringMapParameterNode::StringMap{
            { "analysis_view", "image" },
            { "channels", "0" },
            { "height", "0" },
            { "label_path", "" },
            { "offset", "0x0x0" },
            { "width", "0" },
        }).as<nvneural::IParameterNode>();
        status = pLayer_output->loadFromParameters(pParameterNode.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pNetwork->pushLayer(pLayer_output.get());
        if (nvneural::failed(status)) return status;
    }
    // Connect layer inputs
    {
        status = pLayer_enc_conv0->setInputLayer(0, pLayer_input.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv1->setInputLayer(0, pLayer_enc_conv0.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_pool1->setInputLayer(0, pLayer_enc_conv1.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv2->setInputLayer(0, pLayer_pool1.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_pool2->setInputLayer(0, pLayer_enc_conv2.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv3->setInputLayer(0, pLayer_pool2.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_pool3->setInputLayer(0, pLayer_enc_conv3.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv4->setInputLayer(0, pLayer_pool3.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_pool4->setInputLayer(0, pLayer_enc_conv4.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv5a->setInputLayer(0, pLayer_pool4.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_enc_conv5b->setInputLayer(0, pLayer_enc_conv5a.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_upsample4->setInputLayer(0, pLayer_enc_conv5b.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_concat->setInputLayer(0, pLayer_upsample4.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_concat->setInputLayer(1, pLayer_pool3.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv4a->setInputLayer(0, pLayer_concat.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv4b->setInputLayer(0, pLayer_dec_conv4a.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_upsample3->setInputLayer(0, pLayer_dec_conv4b.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_conca3->setInputLayer(0, pLayer_upsample3.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_conca3->setInputLayer(1, pLayer_pool2.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv3a->setInputLayer(0, pLayer_conca3.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv3b->setInputLayer(0, pLayer_dec_conv3a.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_upsample2->setInputLayer(0, pLayer_dec_conv3b.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_conca2->setInputLayer(0, pLayer_upsample2.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_conca2->setInputLayer(1, pLayer_pool1.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv2a->setInputLayer(0, pLayer_conca2.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv2b->setInputLayer(0, pLayer_dec_conv2a.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_upsample1->setInputLayer(0, pLayer_dec_conv2b.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_conca1->setInputLayer(0, pLayer_upsample1.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_conca1->setInputLayer(1, pLayer_input.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv1a->setInputLayer(0, pLayer_conca1.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv1b->setInputLayer(0, pLayer_dec_conv1a.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_dec_conv0->setInputLayer(0, pLayer_dec_conv1b.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
        status = pLayer_output->setInputLayer(0, pLayer_dec_conv0.get());
        CHECK_NETWORK_VIOLATION(pNetwork3);
        if (nvneural::failed(status)) return status;
    }
    return nvneural::NeuralResult::Success;
}

